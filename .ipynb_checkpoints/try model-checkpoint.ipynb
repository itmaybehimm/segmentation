{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe551786-cc7e-498f-a626-7cefd9649c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers,models\n",
    "from keras.applications import VGG16\n",
    "from matplotlib import pyplot as plt\n",
    "from keras import backend as K\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "340f1301-549d-493c-81aa-d516c2316f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def vgg16_feature_extractor(input_shape):\n",
    "#     # Create VGG16 base model\n",
    "#     base_model = VGG16(include_top=False, input_shape=input_shape,weights='imagenet')\n",
    "\n",
    "#     # Freeze the layers of the base model\n",
    "#     for layer in base_model.layers:\n",
    "#         layer.trainable = False\n",
    "\n",
    "#     # Get the output of the base model\n",
    "#     output = base_model.output\n",
    "\n",
    "#     # Flatten the output feature vectors\n",
    "#     output = layers.GlobalAveragePooling2D()(output)\n",
    "\n",
    "#     # Create the model\n",
    "#     model = models.Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "#     return model\n",
    "\n",
    "\n",
    "# def build_siamese_vgg16(input_shape):\n",
    "#     # Define the input layer for the first image\n",
    "#     input_a = layers.Input(shape=input_shape, name='input_a')\n",
    "#     # Define the input layer for the second image\n",
    "#     input_b = layers.Input(shape=input_shape, name='input_b')\n",
    "\n",
    "#     # data_augmentation = tf.keras.Sequential([\n",
    "#     #   layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "#     #   layers.RandomRotation(0.2),\n",
    "#     # ], name = \"data_augmentation\")\n",
    "#     # augmented_input_a = data_augmentation(input_a)\n",
    "#     # augmented_input_b = data_augmentation(input_b)\n",
    "#     # Define the VGG16 model (excluding the top layers)\n",
    "#     base_model = vgg16_feature_extractor(input_shape)\n",
    "\n",
    "\n",
    "#     # Get the output feature vectors from the base model for both inputs\n",
    "#     output_a = base_model(input_a)\n",
    "#     output_b = base_model(input_b)\n",
    "\n",
    "#     concatenated_features = layers.Concatenate()([output_a, output_b])\n",
    "\n",
    "#     # Distance calculation\n",
    "#     distance = layers.Lambda(lambda x: K.abs(x[0] - x[1]), name='distance')([output_a, output_b])\n",
    "\n",
    "#     # Output layer\n",
    "#     output = layers.Dense(1, activation='sigmoid', name='output')(distance)\n",
    "\n",
    "#     # Create the Siamese model\n",
    "#     siamese_model = models.Model(inputs=[input_a, input_b], outputs=output, name='siamese_vgg16')\n",
    "\n",
    "#     return siamese_model\n",
    "\n",
    "# # Set the input shape for the VGG16 model\n",
    "# input_shape = (224, 224, 3)\n",
    "\n",
    "# # Build the Siamese VGG16 twins model\n",
    "\n",
    "# # model = build_siamese_vgg16(input_shape)\n",
    "\n",
    "# # Compile the model with contrastive loss\n",
    "\n",
    "\n",
    "# # Display the model summary\n",
    "# # model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0935c46c-4aa5-4042-905f-d5d3812c8360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(optimizer =tf.keras.optimizers.legacy.Adam(learning_rate=0.01),\n",
    "#                         loss = tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "#                         metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39e6bf3c-25d1-4049-8a9b-6b633da4dbaa",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "Exception encountered when calling layer \"distance\" (type Lambda).\n\nname 'K' is not defined\n\nCall arguments received by layer \"distance\" (type Lambda):\n  • inputs=['tf.Tensor(shape=(None, 512), dtype=float32)', 'tf.Tensor(shape=(None, 512), dtype=float32)']\n  • mask=None\n  • training=None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcurrent.keras\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43msafe_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/py310tf2/lib/python3.10/site-packages/keras/src/saving/saving_api.py:254\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[1;32m    250\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    251\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe following argument(s) are not supported \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    252\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith the native Keras format: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    253\u001b[0m         )\n\u001b[0;32m--> 254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msaving_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m        \u001b[49m\u001b[43msafe_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafe_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;66;03m# Legacy case.\u001b[39;00m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m legacy_sm_saving_lib\u001b[38;5;241m.\u001b[39mload_model(\n\u001b[1;32m    263\u001b[0m     filepath, custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects, \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    264\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/py310tf2/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:281\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    278\u001b[0m             asset_store\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 281\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/py310tf2/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:246\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;66;03m# Construct the model from the configuration file in the archive.\u001b[39;00m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ObjectSharingScope():\n\u001b[0;32m--> 246\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mdeserialize_keras_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafe_mode\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    250\u001b[0m all_filenames \u001b[38;5;241m=\u001b[39m zf\u001b[38;5;241m.\u001b[39mnamelist()\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _VARS_FNAME \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m all_filenames:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/py310tf2/lib/python3.10/site-packages/keras/src/saving/serialization_lib.py:728\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m safe_mode_scope \u001b[38;5;241m=\u001b[39m SafeModeScope(safe_mode)\n\u001b[1;32m    727\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m custom_obj_scope, safe_mode_scope:\n\u001b[0;32m--> 728\u001b[0m     instance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43minner_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    729\u001b[0m     build_config \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbuild_config\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    730\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m build_config:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/py310tf2/lib/python3.10/site-packages/keras/src/engine/training.py:3330\u001b[0m, in \u001b[0;36mModel.from_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m   3322\u001b[0m revivable_as_functional \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   3323\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01min\u001b[39;00m {functional\u001b[38;5;241m.\u001b[39mFunctional, Model}\n\u001b[1;32m   3324\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m argspec\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m1\u001b[39m:] \u001b[38;5;241m==\u001b[39m functional_init_args\n\u001b[1;32m   3325\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m (argspec\u001b[38;5;241m.\u001b[39mvarargs \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margs\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m argspec\u001b[38;5;241m.\u001b[39mvarkw \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   3326\u001b[0m )\n\u001b[1;32m   3327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_functional_config \u001b[38;5;129;01mand\u001b[39;00m revivable_as_functional:\n\u001b[1;32m   3328\u001b[0m     \u001b[38;5;66;03m# Revive Functional model\u001b[39;00m\n\u001b[1;32m   3329\u001b[0m     \u001b[38;5;66;03m# (but not Functional subclasses with a custom __init__)\u001b[39;00m\n\u001b[0;32m-> 3330\u001b[0m     inputs, outputs, layers \u001b[38;5;241m=\u001b[39m \u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreconstruct_from_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3331\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\n\u001b[1;32m   3332\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3333\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(\n\u001b[1;32m   3334\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs, outputs\u001b[38;5;241m=\u001b[39moutputs, name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   3335\u001b[0m     )\n\u001b[1;32m   3336\u001b[0m     functional\u001b[38;5;241m.\u001b[39mconnect_ancillary_layers(model, layers)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/py310tf2/lib/python3.10/site-packages/keras/src/engine/functional.py:1505\u001b[0m, in \u001b[0;36mreconstruct_from_config\u001b[0;34m(config, custom_objects, created_layers)\u001b[0m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m layer_nodes:\n\u001b[1;32m   1504\u001b[0m     node_data \u001b[38;5;241m=\u001b[39m layer_nodes[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m-> 1505\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mprocess_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_data\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1506\u001b[0m         layer_nodes\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m   1507\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1508\u001b[0m         \u001b[38;5;66;03m# If a node can't be processed, stop processing the\u001b[39;00m\n\u001b[1;32m   1509\u001b[0m         \u001b[38;5;66;03m# nodes of the current layer to maintain node ordering.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/py310tf2/lib/python3.10/site-packages/keras/src/engine/functional.py:1445\u001b[0m, in \u001b[0;36mreconstruct_from_config.<locals>.process_node\u001b[0;34m(layer, node_data)\u001b[0m\n\u001b[1;32m   1438\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(layer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_preserve_input_structure_in_config\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1440\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m layer\u001b[38;5;241m.\u001b[39m_preserve_input_structure_in_config\n\u001b[1;32m   1441\u001b[0m ):\n\u001b[1;32m   1442\u001b[0m     input_tensors \u001b[38;5;241m=\u001b[39m base_layer_utils\u001b[38;5;241m.\u001b[39munnest_if_single_tensor(\n\u001b[1;32m   1443\u001b[0m         input_tensors\n\u001b[1;32m   1444\u001b[0m     )\n\u001b[0;32m-> 1445\u001b[0m output_tensors \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_tensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;66;03m# Update node index map.\u001b[39;00m\n\u001b[1;32m   1448\u001b[0m output_index \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(output_tensors)[\n\u001b[1;32m   1449\u001b[0m     \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   1450\u001b[0m ]\u001b[38;5;241m.\u001b[39m_keras_history\u001b[38;5;241m.\u001b[39mnode_index\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/py310tf2/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m<ipython-input-66-7a38a7980d05>:26\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: Exception encountered when calling layer \"distance\" (type Lambda).\n\nname 'K' is not defined\n\nCall arguments received by layer \"distance\" (type Lambda):\n  • inputs=['tf.Tensor(shape=(None, 512), dtype=float32)', 'tf.Tensor(shape=(None, 512), dtype=float32)']\n  • mask=None\n  • training=None"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('current.keras',safe_mode=False)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "599d9ecd-757d-46a0-b727-780cda17ff64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path=os.path.join(\"mejan\",\"chalde_plz_FINE19_1.h5\")\n",
    "# model.load_weights(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbe963fa-5b9a-4f83-80ff-dac19a93118b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_image(image_path):\n",
    "\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_bmp(image, channels=0)\n",
    "    # image=tf.image.grayscale_to_rgb(image)\n",
    "\n",
    "    image = tf.image.resize(image, size = (224,224))\n",
    "    image = image/255.0 \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3241252-fa24-4730-978b-6e1fb6457a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "img1=os.path.join(\"all-images-iit-normalized-2\",\"001_01_L.bmp\")\n",
    "img2=os.path.join(\"all-images-iit-normalized-2\",\"001_02_L.bmp\")\n",
    "img3=os.path.join(\"all-images-iit-normalized-2\",\"003_07_L.bmp\")\n",
    "img4=os.path.join(\"all-images-iit-normalized-2\",\"003_03_L.bmp\")\n",
    "img5=os.path.join(\"all-images-iit-normalized-2\",\"029_08_R.bmp\")\n",
    "img6=os.path.join(\"all-images-iit-normalized-2\",\"041_07_R.bmp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c88e006-4d05-4863-84c6-54f51edfc81a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([224, 224, 3]),\n",
       " TensorShape([224, 224, 3]),\n",
       " TensorShape([224, 224, 3]),\n",
       " TensorShape([224, 224, 3]),\n",
       " TensorShape([224, 224, 3]),\n",
       " TensorShape([224, 224, 3]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img1=load_and_preprocess_image(img1)\n",
    "img2=load_and_preprocess_image(img2)\n",
    "img3=load_and_preprocess_image(img3)\n",
    "img4=load_and_preprocess_image(img4)\n",
    "img5=load_and_preprocess_image(img5)\n",
    "img6=load_and_preprocess_image(img6)\n",
    "\n",
    "img1.shape,img2.shape,img3.shape,img4.shape,img5.shape,img6.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18e849a4-38c3-43e0-8142-f81f31c252f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axs = plt.subplots(2,3, figsize=(8, 8))\n",
    "\n",
    "# # Plot data on each subplot\n",
    "# axs[0, 0].imshow(tf.cast(img1, dtype=tf.int32))\n",
    "# axs[0, 0].set_title('Image 1')\n",
    "\n",
    "# axs[0, 1].imshow(tf.cast(img2, dtype=tf.int32))\n",
    "# axs[0, 1].set_title('Image 2')\n",
    "\n",
    "# axs[0, 2].imshow(tf.cast(img3, dtype=tf.int32))\n",
    "# axs[0, 2].set_title('Image 3')\n",
    "\n",
    "# axs[1, 0].imshow(tf.cast(img4, dtype=tf.int32))\n",
    "# axs[1, 0].set_title('Image 4')\n",
    "\n",
    "# axs[1, 1].imshow(tf.cast(img5, dtype=tf.int32))\n",
    "# axs[1, 1].set_title('Image 5')\n",
    "\n",
    "# axs[1, 2].imshow(tf.cast(img6, dtype=tf.int32))\n",
    "# axs[1, 2].set_title('Image 6')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dcbe7d1c-64f1-4159-8867-43cfe5dafa74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 224, 224, 3)\n",
      "(1, 224, 224, 3)\n",
      "(1, 224, 224, 3)\n",
      "(1, 224, 224, 3)\n",
      "(1, 224, 224, 3)\n",
      "(1, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "# Assuming img1, img2, ..., img6 are your image tensors\n",
    "\n",
    "# Add an extra dimension at the beginning for each image\n",
    "img1 = tf.expand_dims(img1, axis=0)\n",
    "img2 = tf.expand_dims(img2, axis=0)\n",
    "img3 = tf.expand_dims(img3, axis=0)\n",
    "img4 = tf.expand_dims(img4, axis=0)\n",
    "img5 = tf.expand_dims(img5, axis=0)\n",
    "img6 = tf.expand_dims(img6, axis=0)\n",
    "\n",
    "# Print the shape of each image tensor after adding the extra dimension\n",
    "print(img1.shape)  # Output: (1, 244, 244, 3)\n",
    "print(img2.shape)  # Output: (1, 244, 244, 3)\n",
    "print(img3.shape)  # Output: (1, 244, 244, 3)\n",
    "print(img4.shape)  # Output: (1, 244, 244, 3)\n",
    "print(img5.shape)  # Output: (1, 244, 244, 3)\n",
    "print(img6.shape)  # Output: (1, 244, 244, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5838b929-1a27-4429-8796-81c87ba48814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 655ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.96027267]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([img1,img1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e49cbb43-6f96-4c70-b8ec-f6581c0f8344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 721ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.7407202]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([img1,img2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2652b352-64d4-4150-900a-69dcb7127199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 639ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.00414096]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([img1,img3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8990a34b-4a5e-4d4e-8ed5-e6daba6f0634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 725ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.00567866]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([img2,img3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d18facf0-ed3d-49f8-ac36-cf5b1743a04a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 633ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.5736945]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([img3,img4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce631fdb-9b4d-487f-bb9c-7282cd284428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 639ms/step\n",
      "1/1 [==============================] - 1s 629ms/step\n",
      "1/1 [==============================] - 1s 622ms/step\n",
      "1/1 [==============================] - 1s 604ms/step\n",
      "1/1 [==============================] - 1s 674ms/step\n",
      "1/1 [==============================] - 1s 637ms/step\n",
      "1/1 [==============================] - 1s 598ms/step\n",
      "1/1 [==============================] - 1s 623ms/step\n",
      "1/1 [==============================] - 1s 688ms/step\n",
      "1/1 [==============================] - 1s 901ms/step\n",
      "1/1 [==============================] - 1s 603ms/step\n",
      "1/1 [==============================] - 1s 636ms/step\n",
      "1/1 [==============================] - 1s 652ms/step\n",
      "1/1 [==============================] - 1s 601ms/step\n",
      "1/1 [==============================] - 1s 613ms/step\n",
      "Image 1: img1, Image 2: img2, Prediction:[[0.7407202]] : 1\n",
      "Image 1: img1, Image 2: img3, Prediction:[[0.00414096]] : 0\n",
      "Image 1: img1, Image 2: img4, Prediction:[[0.04583964]] : 0\n",
      "Image 1: img1, Image 2: img5, Prediction:[[0.04213378]] : 0\n",
      "Image 1: img1, Image 2: img6, Prediction:[[0.18375196]] : 0\n",
      "Image 1: img2, Image 2: img3, Prediction:[[0.00567866]] : 0\n",
      "Image 1: img2, Image 2: img4, Prediction:[[0.01886606]] : 0\n",
      "Image 1: img2, Image 2: img5, Prediction:[[0.02024704]] : 0\n",
      "Image 1: img2, Image 2: img6, Prediction:[[0.11852754]] : 0\n",
      "Image 1: img3, Image 2: img4, Prediction:[[0.5736945]] : 1\n",
      "Image 1: img3, Image 2: img5, Prediction:[[0.17853732]] : 0\n",
      "Image 1: img3, Image 2: img6, Prediction:[[0.12492856]] : 0\n",
      "Image 1: img4, Image 2: img5, Prediction:[[0.2650101]] : 0\n",
      "Image 1: img4, Image 2: img6, Prediction:[[0.43074572]] : 0\n",
      "Image 1: img5, Image 2: img6, Prediction:[[0.39783382]] : 0\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "# img1=os.path.join(\"Images\",\"h1.bmp\")\n",
    "# img2=os.path.join(\"Images\",\"i1.bmp\")\n",
    "# img3=os.path.join(\"Images\",\"e2.bmp\")\n",
    "# img4=os.path.join(\"Images\",\"d2.bmp\")\n",
    "# img5=os.path.join(\"Images\",\"d1.bmp\")\n",
    "# img6=os.path.join(\"Images\",\"h2.bmp\")\n",
    "# Assuming model is your TensorFlow model\n",
    "for i in range(6):\n",
    "    for j in range(i+1, 6):\n",
    "        img1_name = f'img{i+1}'\n",
    "        img2_name = f'img{j+1}'\n",
    "        img1_data = eval(img1_name)\n",
    "        img2_data = eval(img2_name)\n",
    "        \n",
    "        # Predict for the pair of images (img_i, img_j)\n",
    "        prediction = model.predict([img1_data, img2_data])\n",
    "        predictions.append((img1_name, img2_name, prediction))\n",
    "\n",
    "# Now predictions list contains tuples of image names and predictions for all combinations of images\n",
    "for img1_name, img2_name, prediction in predictions:\n",
    "    print(f\"Image 1: {img1_name}, Image 2: {img2_name}, Prediction:{prediction} : {0 if prediction< 0.5 else 1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a69ee9-5707-4381-ae53-e6961e2e22fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310tf2",
   "language": "python",
   "name": "py310tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
